{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro to Statistical Machine Learning\n",
    "\n",
    "## Lecture 1\n",
    "\n",
    "## Prof. James Sharpnack\n",
    "\n",
    "#### The life satisfaction data example and some of the code is based on the notebook file [01 in Aur√©lien Geron's github page](https://github.com/ageron/handson-ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning\n",
    "\n",
    "A computer program learns from experience, E, with respect to class of tasks, T, and performance measure, P, if its performance at T improves by P with E.\n",
    "\n",
    "Examples of these categories are,\n",
    "- E: data (training)\n",
    "- P: loss (test), reward\n",
    "- T: classification, regression, expert selection, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inference vs. Prediction\n",
    "\n",
    "- statistical inference: is this effect significant? is the model correct? etc.\n",
    "- prediction: does this algorithm predict the response variable well?\n",
    "\n",
    "### terms\n",
    "\n",
    "- *supervised learning*: predicting one variable from many others\n",
    "- *predictor* variables: X variables\n",
    "- *response* variable: Y variable\n",
    "- ``X``: $n \\times p$ design matrix / features\n",
    "- ``Y``: $n$ label vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## I will be using Python 3, for install instructions see \n",
    "## http://anson.ucdavis.edu/~jsharpna/DSBook/unit1/intro.html#installation-and-workflow\n",
    "\n",
    "## The following packages are numpy (linear algebra), pandas (data munging), \n",
    "## sklearn (machine learning), matplotlib (graphics), statsmodels (statistical models)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jsharpna jsharpna 84199 Apr  1  2019 ../../data/winequality-red.csv\r\n"
     ]
    }
   ],
   "source": [
    "## Lines that start with ! run a bash command\n",
    "\n",
    "!ls -l ../../data/winequality-red.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fixed acidity\";\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"\r\n",
      "7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5\r\n",
      "7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5\r\n",
      "7.8;0.76;0.04;2.3;0.092;15;54;0.997;3.26;0.65;9.8;5\r\n",
      "11.2;0.28;0.56;1.9;0.075;17;60;0.998;3.16;0.58;9.8;6\r\n",
      "7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5\r\n",
      "7.4;0.66;0;1.8;0.075;13;40;0.9978;3.51;0.56;9.4;5\r\n",
      "7.9;0.6;0.06;1.6;0.069;15;59;0.9964;3.3;0.46;9.4;5\r\n",
      "7.3;0.65;0;1.2;0.065;15;21;0.9946;3.39;0.47;10;7\r\n",
      "7.8;0.58;0.02;2;0.073;9;18;0.9968;3.36;0.57;9.5;7\r\n"
     ]
    }
   ],
   "source": [
    "!head ../../data/winequality-red.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wine dataset description\n",
    "- 84199 bytes (not large, feel free to load into memory)\n",
    "- header with quotations \" in the text\n",
    "- each line has floats without quotations\n",
    "- each datum separated by ;\n",
    "\n",
    "Some Python basics:\n",
    "- file input/output\n",
    "- [f(a) for a in L] list comprehensions\n",
    "- iterables, basic types, built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "datapath = \"../../data/\"\n",
    "with open(datapath + 'winequality-red.csv','r') as winefile:\n",
    "    header = winefile.readline()\n",
    "    wine_list = [line.strip().split(';') for line in winefile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "wine_ar = np.array(wine_list,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "names = [name.strip('\"') for name in header.strip().split(';')]\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Subselect the predictor X and response y\n",
    "y = wine_ar[:,-1]\n",
    "X = wine_ar[:,:-1]\n",
    "n,p = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599,), (1599, 11))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, X.shape #just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = np.hstack((np.ones((n,1)),X)) #add intercept\n",
    "wine_ols = sm.OLS(y,X) #Initialize the OLS \n",
    "wine_res = wine_ols.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.361</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.356</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   81.35</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>1.79e-145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:50:38</td>     <th>  Log-Likelihood:    </th> <td> -1569.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1599</td>      <th>  AIC:               </th> <td>   3162.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1587</td>      <th>  BIC:               </th> <td>   3227.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   21.9652</td> <td>   21.195</td> <td>    1.036</td> <td> 0.300</td> <td>  -19.607</td> <td>   63.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0250</td> <td>    0.026</td> <td>    0.963</td> <td> 0.336</td> <td>   -0.026</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -1.0836</td> <td>    0.121</td> <td>   -8.948</td> <td> 0.000</td> <td>   -1.321</td> <td>   -0.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1826</td> <td>    0.147</td> <td>   -1.240</td> <td> 0.215</td> <td>   -0.471</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0163</td> <td>    0.015</td> <td>    1.089</td> <td> 0.276</td> <td>   -0.013</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.8742</td> <td>    0.419</td> <td>   -4.470</td> <td> 0.000</td> <td>   -2.697</td> <td>   -1.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0044</td> <td>    0.002</td> <td>    2.009</td> <td> 0.045</td> <td>    0.000</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0033</td> <td>    0.001</td> <td>   -4.480</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  -17.8812</td> <td>   21.633</td> <td>   -0.827</td> <td> 0.409</td> <td>  -60.314</td> <td>   24.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.4137</td> <td>    0.192</td> <td>   -2.159</td> <td> 0.031</td> <td>   -0.789</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.9163</td> <td>    0.114</td> <td>    8.014</td> <td> 0.000</td> <td>    0.692</td> <td>    1.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.2762</td> <td>    0.026</td> <td>   10.429</td> <td> 0.000</td> <td>    0.224</td> <td>    0.328</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>27.376</td> <th>  Durbin-Watson:     </th> <td>   1.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  40.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.168</td> <th>  Prob(JB):          </th> <td>1.27e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.708</td> <th>  Cond. No.          </th> <td>1.13e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.13e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.361\n",
       "Model:                            OLS   Adj. R-squared:                  0.356\n",
       "Method:                 Least Squares   F-statistic:                     81.35\n",
       "Date:                Thu, 19 Mar 2020   Prob (F-statistic):          1.79e-145\n",
       "Time:                        16:50:38   Log-Likelihood:                -1569.1\n",
       "No. Observations:                1599   AIC:                             3162.\n",
       "Df Residuals:                    1587   BIC:                             3227.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         21.9652     21.195      1.036      0.300     -19.607      63.538\n",
       "x1             0.0250      0.026      0.963      0.336      -0.026       0.076\n",
       "x2            -1.0836      0.121     -8.948      0.000      -1.321      -0.846\n",
       "x3            -0.1826      0.147     -1.240      0.215      -0.471       0.106\n",
       "x4             0.0163      0.015      1.089      0.276      -0.013       0.046\n",
       "x5            -1.8742      0.419     -4.470      0.000      -2.697      -1.052\n",
       "x6             0.0044      0.002      2.009      0.045       0.000       0.009\n",
       "x7            -0.0033      0.001     -4.480      0.000      -0.005      -0.002\n",
       "x8           -17.8812     21.633     -0.827      0.409     -60.314      24.551\n",
       "x9            -0.4137      0.192     -2.159      0.031      -0.789      -0.038\n",
       "x10            0.9163      0.114      8.014      0.000       0.692       1.141\n",
       "x11            0.2762      0.026     10.429      0.000       0.224       0.328\n",
       "==============================================================================\n",
       "Omnibus:                       27.376   Durbin-Watson:                   1.757\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.965\n",
       "Skew:                          -0.168   Prob(JB):                     1.27e-09\n",
       "Kurtosis:                       3.708   Cond. No.                     1.13e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.13e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear model\n",
    "\n",
    "$$f_\\beta(x_i) = \\beta_0 + \\sum_{j=1}^p \\beta_j x_{i,j}$$\n",
    "\n",
    "### Inference in linear models\n",
    "\n",
    "- statistically test for significance of effects\n",
    "- requires normality assumptions, homoscedasticity, linear model is correct\n",
    "- hard to obtain significance for individual effect under colinearity\n",
    "\n",
    "### Prediction perspective\n",
    "\n",
    "- think of OLS as a black-box model for predicting $Y | X$\n",
    "- how do we evaluate performance of prediction?\n",
    "- how do we choose between multiple OLS models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised learning\n",
    "\n",
    "Learning machine that takes $p$-dimensional data $x_i = (x_{i,1}, \\ldots, x_{i,p})$ and predicts $y_i \\in \\mathcal Y$. \n",
    "\n",
    "- *Task:* **Predict** $y$ given $x$ as $f_\\beta(x)$\n",
    "- *Performance Metric:* **Loss** measured with some function $\\ell(\\beta; x,y)$\n",
    "- *Experience:* **Fit** the model with training data $\\{x_i,y_i\\}_{i=1}^{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Regression\n",
    "\n",
    "- **Fit**: Compute $\\hat \\beta$ from OLS with training data $\\{x_i,y_i\\}_{i=1}^{n}$\n",
    "- **Predict**: For a new predictor $x_{n+1}$ predict $$\\hat y = f_{\\hat \\beta}(x_{n+1}) = \\hat \\beta_0 + \\sum_{j=1}^p \\hat \\beta_j x_{n+1,j}$$\n",
    "- **Loss**: Observe new response $y_{n+1}$ and see loss $$\\ell(\\hat \\beta; x_{n+1},y_{n+1}) = (f_{\\hat \\beta}(x_{n+1}) - y_{n+1})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "- Look at the [train_test_split documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) and the [LinearRegression documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html); look at the `fit` and `predict` methods for the linear regression\n",
    "- Split the wine data using the `train_test_split` with `test_size` at 50%.\n",
    "- Use the `LinearRegression` class to fit a linear regression on the training data\n",
    "- Predict the wine quality on the test data and compute the average square error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Answer to ex 1.1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size = .5)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_tr,y_tr)\n",
    "\n",
    "y_pred = lr.predict(X_te)\n",
    "MSE = ((y_pred - y_te)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41363624717615793\n",
      "0.636775\n"
     ]
    }
   ],
   "source": [
    "## It is reasonable to compare the MSE to the variance...\n",
    "print(MSE)\n",
    "print(y_te.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## The following uses pandas!\n",
    "\n",
    "datapath = \"../../data/\"\n",
    "oecd_bli = pd.read_csv(datapath + \"oecd_bli_2015.csv\", thousands=',')\n",
    "oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "\n",
    "# Load and prepare GDP per capita data\n",
    "\n",
    "# Download data from http://goo.gl/j1MSKe (=> imf.org)\n",
    "gdp_per_capita = pd.read_csv(datapath+\"gdp_per_capita.csv\", thousands=',', delimiter='\\t',\n",
    "                             encoding='latin1', na_values=\"n/a\")\n",
    "gdp_per_capita = gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"})\n",
    "gdp_per_capita = gdp_per_capita.set_index(\"Country\")\n",
    "\n",
    "full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita, left_index=True, right_index=True)\n",
    "full_country_stats = full_country_stats.sort_values(by=\"GDP per capita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air pollution</th>\n",
       "      <th>Assault rate</th>\n",
       "      <th>Consultation on rule-making</th>\n",
       "      <th>Dwellings without basic facilities</th>\n",
       "      <th>Educational attainment</th>\n",
       "      <th>Employees working very long hours</th>\n",
       "      <th>Employment rate</th>\n",
       "      <th>Homicide rate</th>\n",
       "      <th>Household net adjusted disposable income</th>\n",
       "      <th>Household net financial wealth</th>\n",
       "      <th>...</th>\n",
       "      <th>Time devoted to leisure and personal care</th>\n",
       "      <th>Voter turnout</th>\n",
       "      <th>Water quality</th>\n",
       "      <th>Years in education</th>\n",
       "      <th>Subject Descriptor</th>\n",
       "      <th>Units</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Country/Series-specific Notes</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Estimates Start After</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>18.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.41</td>\n",
       "      <td>67.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>11664.0</td>\n",
       "      <td>6844.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.97</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>8669.998</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.83</td>\n",
       "      <td>61.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>9056.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.89</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>9009.280</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>69.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>19292.0</td>\n",
       "      <td>3412.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.97</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>9054.914</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>12.7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.86</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14095.0</td>\n",
       "      <td>3251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.42</td>\n",
       "      <td>88.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>9437.372</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hungary</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>15442.0</td>\n",
       "      <td>13277.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.04</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>Gross domestic product per capita, current prices</td>\n",
       "      <td>U.S. dollars</td>\n",
       "      <td>Units</td>\n",
       "      <td>See notes for:  Gross domestic product, curren...</td>\n",
       "      <td>12239.894</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Air pollution  Assault rate  Consultation on rule-making  \\\n",
       "Country                                                             \n",
       "Brazil            18.0           7.9                          4.0   \n",
       "Mexico            30.0          12.8                          9.0   \n",
       "Russia            15.0           3.8                          2.5   \n",
       "Turkey            35.0           5.0                          5.5   \n",
       "Hungary           15.0           3.6                          7.9   \n",
       "\n",
       "         Dwellings without basic facilities  Educational attainment  \\\n",
       "Country                                                               \n",
       "Brazil                                  6.7                    45.0   \n",
       "Mexico                                  4.2                    37.0   \n",
       "Russia                                 15.1                    94.0   \n",
       "Turkey                                 12.7                    34.0   \n",
       "Hungary                                 4.8                    82.0   \n",
       "\n",
       "         Employees working very long hours  Employment rate  Homicide rate  \\\n",
       "Country                                                                      \n",
       "Brazil                               10.41             67.0           25.5   \n",
       "Mexico                               28.83             61.0           23.4   \n",
       "Russia                                0.16             69.0           12.8   \n",
       "Turkey                               40.86             50.0            1.2   \n",
       "Hungary                               3.19             58.0            1.3   \n",
       "\n",
       "         Household net adjusted disposable income  \\\n",
       "Country                                             \n",
       "Brazil                                    11664.0   \n",
       "Mexico                                    13085.0   \n",
       "Russia                                    19292.0   \n",
       "Turkey                                    14095.0   \n",
       "Hungary                                   15442.0   \n",
       "\n",
       "         Household net financial wealth          ...            \\\n",
       "Country                                          ...             \n",
       "Brazil                           6844.0          ...             \n",
       "Mexico                           9056.0          ...             \n",
       "Russia                           3412.0          ...             \n",
       "Turkey                           3251.0          ...             \n",
       "Hungary                         13277.0          ...             \n",
       "\n",
       "         Time devoted to leisure and personal care  Voter turnout  \\\n",
       "Country                                                             \n",
       "Brazil                                       14.97           79.0   \n",
       "Mexico                                       13.89           63.0   \n",
       "Russia                                       14.97           65.0   \n",
       "Turkey                                       13.42           88.0   \n",
       "Hungary                                      15.04           62.0   \n",
       "\n",
       "         Water quality  Years in education  \\\n",
       "Country                                      \n",
       "Brazil            72.0                16.3   \n",
       "Mexico            67.0                14.4   \n",
       "Russia            56.0                16.0   \n",
       "Turkey            62.0                16.4   \n",
       "Hungary           77.0                17.6   \n",
       "\n",
       "                                        Subject Descriptor         Units  \\\n",
       "Country                                                                    \n",
       "Brazil   Gross domestic product per capita, current prices  U.S. dollars   \n",
       "Mexico   Gross domestic product per capita, current prices  U.S. dollars   \n",
       "Russia   Gross domestic product per capita, current prices  U.S. dollars   \n",
       "Turkey   Gross domestic product per capita, current prices  U.S. dollars   \n",
       "Hungary  Gross domestic product per capita, current prices  U.S. dollars   \n",
       "\n",
       "         Scale                      Country/Series-specific Notes  \\\n",
       "Country                                                             \n",
       "Brazil   Units  See notes for:  Gross domestic product, curren...   \n",
       "Mexico   Units  See notes for:  Gross domestic product, curren...   \n",
       "Russia   Units  See notes for:  Gross domestic product, curren...   \n",
       "Turkey   Units  See notes for:  Gross domestic product, curren...   \n",
       "Hungary  Units  See notes for:  Gross domestic product, curren...   \n",
       "\n",
       "         GDP per capita  Estimates Start After  \n",
       "Country                                         \n",
       "Brazil         8669.998                 2014.0  \n",
       "Mexico         9009.280                 2015.0  \n",
       "Russia         9054.914                 2015.0  \n",
       "Turkey         9437.372                 2013.0  \n",
       "Hungary       12239.894                 2015.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_country_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Life Satisfaction Index')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = full_country_stats.plot(\"GDP per capita\",'Life satisfaction',kind='scatter')\n",
    "plt.title('Life Satisfaction Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "keepvars = full_country_stats.dtypes[full_country_stats.dtypes == float].index.values\n",
    "keepvars = keepvars[:-1]\n",
    "country = full_country_stats[keepvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Y = np.array(country['Life satisfaction'])\n",
    "del country['Life satisfaction']\n",
    "X_vars = country.columns.values\n",
    "X = np.array(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def loss(yhat,y):\n",
    "    \"\"\"sqr error loss\"\"\"\n",
    "    return (yhat - y)**2\n",
    "\n",
    "def fit(X,Y):\n",
    "    \"\"\"fit the OLS from training w/ intercept\"\"\"\n",
    "    lin1 = LinearRegression(fit_intercept=True) # OLS from sklearn\n",
    "    lin1.fit(X,Y) # fit OLS\n",
    "    return np.append(lin1.intercept_,lin1.coef_) # return betahat\n",
    "\n",
    "def predict(x, betahat):\n",
    "    \"\"\"predict for point x\"\"\"\n",
    "    return betahat[0] + x @ betahat[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- Supervised learning task is to predict $Y$ given $X$\n",
    "- Fit is using training data to fit parameters\n",
    "- Predict uses the fitted parameters to do prediction\n",
    "- Loss is a function that says how poorly you did on datum $x_i,y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Risk and Empirical Risk\n",
    "\n",
    "Given a loss $\\ell(\\theta; X,Y)$, for parameters $\\theta$, the *risk* is \n",
    "$$\n",
    "R(\\theta) = \\mathbb E \\ell(\\theta; X,Y).\n",
    "$$\n",
    "\n",
    "And given training data $\\{x_i,y_i\\}_{i=1}^{n_0}$ (drawn iid to $X,Y$), then the *empirical risk* is\n",
    "$$\n",
    "R_n(\\theta) = \\frac 1n \\sum_{i=1}^n \\ell(\\theta; x_i, y_i).\n",
    "$$\n",
    "Notice that $\\mathbb E R_n(\\theta) = R(\\theta)$ for fixed $\\theta$.\n",
    "\n",
    "For a class of parameters $\\Theta$, the *empirical risk minimizer (ERM)* is the \n",
    "$$\n",
    "\\hat \\theta = \\arg \\min_{\\theta \\in \\Theta} R_n(\\theta)\n",
    "$$\n",
    "(may not be unique)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### OLS is the ERM\n",
    "\n",
    "OLS minimizes the following objective,\n",
    "$$\n",
    "R_n(\\beta) = \\frac 1n \\sum_{i=1}^n \\left(y_i - x_i^\\top \\beta - \\beta_0 \\right)^2\n",
    "$$\n",
    "with respect to $\\beta,\\beta_0$.\n",
    "This is the ERM for square error loss and linear predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why is ERM a good idea?\n",
    "\n",
    "For a fixed $\\theta$ we know by the Law of Large Numbers (as long as expectations exist and data is iid),\n",
    "$$\n",
    "R_n(\\theta) = \\frac 1n \\sum_{i=1}^n \\ell(\\theta; x_i, y_i) \\rightarrow \\mathbb E \\ell(\\theta; X,Y) = R(\\theta),\n",
    "$$\n",
    "where convergence is in probability (or almost surely).\n",
    "We want to minimize $R(\\theta)$ so $R_n(\\theta)$ is a pretty good surrogate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Binary classification\n",
    "\n",
    "Mortgage insurer pays the mortgage company if the insuree defaults on loan.  To determine how much to charge want to predict if they will default (1) or not (0).\n",
    "\n",
    "An actuary (from 19th century) says that people that are young (less than 30) are irresponsible and will not insure them.  Let $x$ be the age in years, $y = 1$ if they default, and $\\theta = 30$.\n",
    "\n",
    "$$\n",
    "g_\\theta(x) = \\left\\{ \\begin{array}{ll}\n",
    "1, &x < \\theta\\\\\n",
    "0, &x \\ge \\theta \n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "0-1 loss is\n",
    "$$\n",
    "\\ell_{0-1}(\\theta; X,Y) = \\mathbf 1 \\{g_\\theta(X)\\ne Y\\}.\n",
    "$$\n",
    "The risk is\n",
    "$$\n",
    "R(\\theta) = \\mathbb E \\mathbf 1 \\{g_\\theta(X)\\ne Y\\} = \\mathbb P \\{ g_\\theta(X) \\ne Y \\}.\n",
    "$$\n",
    "How well will he do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "Want to summarize/compress/learn distribution of $X$.  Clustering for example is the problem of assigning each datum to a cluster.\n",
    "<img width=\"500px\" src=\"kmeans.png\">\n",
    "\n",
    "Image from https://rpubs.com/cyobero/k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Clustering for example is the problem of assigning each datum to a cluster in index set $[C] = \\{1,\\ldots,C\\}$ for cluster centers $z_k$,\n",
    "$$\n",
    "\\theta = \\left\\{ \\textrm{cluster centers, } \\{ z_k \\}_{k=1}^C \\subset \\mathbb R^p, \\textrm{ cluster assignments, } \\sigma:[n] \\to [C] \\right\\}\n",
    "$$\n",
    "The loss is \n",
    "$$\n",
    "\\ell(\\theta;x_i) = \\| x_i - z_{\\sigma(i)} \\|^2 = \\sum_{j=1}^p (x_{i,j} - z_{\\sigma(i),j})^2.\n",
    "$$\n",
    "Loss, risk, and empirical risk still can be defined, but many concepts are not the same (such as bias-variance tradeoff)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issue with training error in Supervised learning.\n",
    "\n",
    "Let $\\hat \\theta$ be the ERM, then the *training error* is\n",
    "$$\n",
    "R_n(\\hat \\theta) = \\min_{\\theta \\in \\Theta} R_n(\\theta)\n",
    "$$\n",
    "which does NOT converge to $R(\\theta)$ because\n",
    "$$\n",
    "\\mathbb E \\min_\\theta R_n(\\theta) \\ne \\min_{\\theta} \\mathbb E R_n(\\theta) = \\min_\\theta R(\\theta).\n",
    "$$\n",
    "\n",
    "### Solution\n",
    "\n",
    "Split the data randomly into training and test sets: \n",
    "- train $\\hat \\theta$ with the training data\n",
    "- test $\\hat \\theta$ with the test data\n",
    "\n",
    "Because the test data is independent of $\\hat \\theta$ we can think of the training process as fixed and test error is now unbiased for risk of $\\hat \\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## randomly shuffle data and split\n",
    "n,p = X.shape\n",
    "Ind = np.arange(n) \n",
    "np.random.shuffle(Ind) \n",
    "train_size = 2 * n // 3 +1 # set training set size\n",
    "X_tr, X_te = X[Ind[:train_size],:], X[Ind[train_size:],:]\n",
    "Y_tr, Y_te = Y[Ind[:train_size]], Y[Ind[train_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## compute losses on test set\n",
    "betahat = fit(X_tr,Y_tr)\n",
    "Y_hat_te = [predict(x,betahat) for x in X_te]\n",
    "test_losses = [loss(yhat,y) for yhat,y in zip(Y_hat_te,Y_te)]\n",
    "\n",
    "## compute losses on train set\n",
    "Y_hat_tr = [predict(x,betahat) for x in X_tr]\n",
    "train_losses = [loss(yhat,y) for yhat,y in zip(Y_hat_tr,Y_tr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.444625512977249e-22,\n",
       " 4.789408058424708e-22,\n",
       " 3.4382433844272955e-22,\n",
       " 6.386933748575762e-23,\n",
       " 7.351858499749134e-22,\n",
       " 1.3409297804094917e-21,\n",
       " 2.9197810842621935e-21,\n",
       " 1.039531398291255e-21,\n",
       " 5.607714332892798e-22,\n",
       " 2.3122614381851545e-23,\n",
       " 2.1335721653214664e-21,\n",
       " 5.6447928149221026e-24,\n",
       " 3.3087224502121107e-22,\n",
       " 1.1408544600062694e-21,\n",
       " 8.496586931809782e-21,\n",
       " 1.2751479190787854e-21,\n",
       " 6.064590983206163e-23,\n",
       " 1.91731144178247e-22,\n",
       " 1.7474912689673094e-21,\n",
       " 4.864338989694648e-22,\n",
       " 1.550858667716521e-21,\n",
       " 3.408013204286884e-21,\n",
       " 2.363191630612292e-21,\n",
       " 2.8989893905610626e-21,\n",
       " 8.333312348132911e-23]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1111.340064728651,\n",
       " 0.6255327739667467,\n",
       " 182.73909226856128,\n",
       " 1662.5641512445711,\n",
       " 1187.18292683525,\n",
       " 1909.680414765608,\n",
       " 1171.813096477374,\n",
       " 17.875942381202396,\n",
       " 488.6096378479109,\n",
       " 5445.915952121844,\n",
       " 522.1742807860538]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss: 1.376951437853411e-21\n",
      "test avg loss: 1245.5019174755448\n",
      "n p : 36 24\n"
     ]
    }
   ],
   "source": [
    "print(\"train avg loss: {}\\ntest avg loss: {}\".format(np.mean(train_losses), np.mean(test_losses)))\n",
    "print(\"n p :\",n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(X,Y,split_pr = 0.5):\n",
    "    \"\"\"train-test split\"\"\"\n",
    "    n,p = X.shape\n",
    "    Ind = np.arange(n) \n",
    "    np.random.shuffle(Ind) \n",
    "    train_size = int(split_pr * n) # set training set size\n",
    "    X_tr, X_te = X[Ind[:train_size],:], X[Ind[train_size:],:]\n",
    "    Y_tr, Y_te = Y[Ind[:train_size]], Y[Ind[train_size:]]\n",
    "    return (X_tr,Y_tr), (X_te, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Y = wine_ar[:,-1]\n",
    "X = wine_ar[:,:-1]\n",
    "(X_tr,Y_tr), (X_te, Y_te) = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## compute losses on test set\n",
    "betahat = fit(X_tr,Y_tr)\n",
    "Y_hat_te = [predict(x,betahat) for x in X_te]\n",
    "test_losses = [loss(yhat,y) for yhat,y in zip(Y_hat_te,Y_te)]\n",
    "\n",
    "## compute losses on train set\n",
    "Y_hat_tr = [predict(x,betahat) for x in X_tr]\n",
    "train_losses = [loss(yhat,y) for yhat,y in zip(Y_hat_tr,Y_tr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss: 0.4120109503777993\n",
      "test avg loss: 0.42469372283837814\n"
     ]
    }
   ],
   "source": [
    "print(\"train avg loss: {}\\ntest avg loss: {}\".format(np.mean(train_losses), np.mean(test_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- Want to minimize true risk (expected loss)\n",
    "- Instead we minimize empirical risk (training error)\n",
    "- Training error is now biased, so we do training test split"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
